title: 'GBS: Kapitel 2: Prozess und Prozessorverwaltung'
author: hmelder
id: 311133220
cards:
- type: md_basic
  id: 0  # (generated)
  front: Was sind die 5 Stufen um C Quellcode zu einem ausführbaren Programm zu transformieren?
  back: |+
    1. Präprozessor (Auflösen von Makros und anderen Direktiven wie #include)
    2. Compiler (Übersetzer von C in Assembler)
    3. Assembler (Übersetzer von Assemblersprache in ISA-spezifischen Maschinencode)
    4. Linker (Binden von einzelnen Modulen zu einer ausführbaren Datei)
    5. Loader des Betriebsystems (Laden der gebundenen Objekte in den Speicher)

- type: md_basic
  id: 1  # (generated)
  front: Was sind die IOPL Bits im Flag Register eines x86 Prozessors
  back: |+
    Die I/O Privilege Level (IOPL) Bits spezifizieren die aktuelle Privilegienlevel.

    Die IOPL Bits im Flag Register eines x86 Prozessors definieren das
    Privilegienlevel für I/O-Operationen. Es gibt vier Privilegienebenen (Ringe 0
    bis 3), wobei Ring 0 das höchste Privileg und Ring 3 das niedrigste darstellt.

- type: md_basic
  id: 2  # (generated)
  front: Wie sieht ein Prozess im Speicher aus (x86)
  back: |+
    Von 0xFFFF...FFFF nach 0x0000...0000!

    1. Stack - Beginnt bei der höchsten Adresse und wächst nach unten. Enthält lokale Variablen und Funktionsaufrufe.
    2. Heap - Wächst dynamisch nach oben, liegt direkt über dem Data-Segment.
    3. Data - Enthält globale und statische Variablen; liegt über dem Code-Segment.
    4. Code/Text - Befindet sich im unteren Teil des Adressraums; enthält ausführbaren Programmcode.

- type: md_basic
  id: 3  # (generated)
  front: Was ist ein Prozesskontext?
  back: |+
    Der Prozesskontext umfasst alle Informationen, die ein Betriebssystem über einen
    Prozess speichert, um dessen Ausführungszustand zu verwalten.

- type: md_basic
  id: 4  # (generated)
  front: Was ist der virtuelle Addressraum?
  back: |+
    Der virtuelle Addressraum ist eine Abstraktion des physischen Speichers.
    Jeder Prozess verfügt über einen eigenen Addressraum, die voneinnander
    *abgeschottet* sind.


- type: md_basic
  id: 5  # (generated)
  front: 'Prozesskontext im Betriebssystem: Registerzustände'
  back: |+
    - Registerinhalte
    - Program Counter
    - Stack Pointer
    - Statusregister

- type: md_basic
  id: 6  # (generated)
  front: 'Prozesskontext im Betriebssystem: Prozessidentifikation und -zustand'
  back: |+
    - Prozesszustand
    - Priorität
    - Process ID (PID)
    - Parent PID (PPID)
    - Process Group ID (PGID)

- type: md_basic
  id: 7  # (generated)
  front: 'Prozesskontext im Betriebssystem: Ressourcenverweise und Sicherheitskontext'
  back: |+
    - Pointer auf Speichersegmente
    - Größe der Segmente
    - Dateideskriptoren
    - User ID (UID)
    - Group ID (GID)

- type: md_basic
  id: 8  # (generated)
  front: Warum ist die Prozess-Verarbeitung oftmals nur quasi-parallel?
  back: |+
    In Einprozessorsystemen kann die CPU tatsächlich nur einen Prozess gleichzeitig
    ausführen. Quasi-Parallelität entsteht durch schnelles Umschalten zwischen
    Prozessen (Scheduling), wodurch der Eindruck simultaner Ausführung entsteht.

- type: md_basic
  id: 9  # (generated)
  front: Wie beeinflusst der I/O-Warteanteil p die CPU-Auslastung bei n Prozessen?
  back: |+
    Ist der Anteil der Wartezeit auf I/O für einen Prozess p, so ist die erwartete
    CPU-Auslastung bei n gleichzeitig laufenden Prozessen probabilistisch 1 - p^n.

- type: md_basic
  id: 10  # (generated)
  front: Was sind die Zustände eines Prozesses?
  back: |+
    - **ready**: Der Prozess ist bereit zur Ausführung und wartet auf Zuweisung eines Prozessors.
    - **running**: Der Prozess wird aktuell auf dem Prozessor ausgeführt.
    - **blocked/waiting**: Der Prozess kann nicht fortgesetzt werden, bis ein bestimmtes Ereignis eintritt.
    - **swapped out/ausgelagert**: Der Prozess wurde aus dem Arbeitsspeicher ausgelagert.
    - **swapped in/eingelagert**: Ein ausgelagerter Prozess wird wieder in den Arbeitsspeicher geladen.

- type: md_basic
  id: 11  # (generated)
  front: Was initiiert der Zustandsübergang 'add' bei einem Prozess?
  back: |+
    Der Zustandsübergang 'add' fügt einen neu erzeugten Prozess zur Menge der rechenwilligen (ready) Prozesse hinzu.

- type: md_basic
  id: 12  # (generated)
  front: Welche Wirkung hat der Zustandsübergang 'assign' auf einen Prozess?
  back: |+
    Der Zustandsübergang 'assign' ordnet einem Prozess die CPU zu und ändert seinen Status auf 'running'.

- type: md_basic
  id: 13  # (generated)
  front: Durch was wird der Zustandsübergang 'block' bei einem Prozess veranlasst?
  back: |+
    Der Zustandsübergang 'block' wird durch einen I/O-Aufruf oder eine
    Synchronisationsoperation ausgelöst und versetzt den Prozess in den Zustand
    'blocked/waiting'.

- type: md_basic
  id: 14  # (generated)
  front: Wann erfolgt der Zustandsübergang eines Prozesses zurück in 'ready'?
  back: |+
    Der Zustandsübergang zurück in 'ready' erfolgt, nachdem die blockierende
    Operation beendet ist oder die Blockade aufgehoben wurde.

- type: md_basic
  id: 15  # (generated)
  front: Welcher Zustandsübergang wird mit 'resign' beschrieben?
  back: |+
    Der Zustandsübergang 'resign' entzieht einem laufenden Prozess die CPU, wodurch
    er in den Zustand 'ready' zurückkehrt.

- type: md_basic
  id: 16  # (generated)
  front: Was kennzeichnet den Zustandsübergang 'retire' bei einem Prozess?
  back: |+
    Der Zustandsübergang 'retire' tritt ein, wenn ein Prozess seine Ausführung
    beendet und aus dem System entfernt wird.

- type: md_basic
  id: 17  # (generated)
  front: Was resultiert aus dem Zustandsübergang 'swap out' für einen Prozess?
  back: |+
    Der Zustandsübergang 'swap out' lagert einen Prozess aus dem Arbeitsspeicher in
    die Swap-Datei auf der Festplatte aus.

- type: md_basic
  id: 18  # (generated)
  front: Welchen Zustand erreicht ein Prozess durch den Zustandsübergang 'swap in'?
  back: |+
    Durch den Zustandsübergang 'swap in' wird ein ausgelagerter Prozess wieder in
    den Arbeitsspeicher geladen.

- type: md_basic
  id: 19  # (generated)
  front: Prozess vs. Thread
  back: |+
    - **Prozess**: Einzelne Ausführungseinheit mit eigenem Adressraum, die Ressourcen wie CPU und Speicher nutzt.
    - **Thread**: Leichtgewichtiger Prozess innerhalb eines Prozesses, der einen eigenen Kontrollfluss hat, aber Ressourcen mit anderen Threads teilt.

- type: md_basic
  id: 20  # (generated)
  front: Warum lässt sich ein Prozess und Thread konzeptuell trennen?
  back: |+
    Ressourcen und Kontrollfluss sind unabhängige Konzepte und lassen sich trennen.

- type: md_basic
  id: 21  # (generated)
  front: Eigenschaften eines Threads
  back: |+
    - Abstraktion eines physischen Prozessors
    - Jeder Prozess hat einen eigenen Kontrollfluss
    - Threads eines Prozesses teilen sich den Addressraum
    - Eigener Befehlzähler

- type: md_basic
  id: 22  # (generated)
  front: Thread-Kontext
  back: "Der Thread-Kontext umfasst u.a:\n- Programmzähler\n- Registerwerte \n- Stackpointer
    auf eigenem Stack\n\n"
- type: md_basic
  id: 23  # (generated)
  front: Was sind die 5 möglichen Zustände eines Threads?
  back: |+
    - (erzeugt)
    - rechenwillig
    - rechnend
    - wartend
    - terminiert

- type: md_basic
  id: 24  # (generated)
  front: Warum haben Threads generell einen geringeren Overhead als Prozesse?
  back: |+
    - Einfache Kommunikation zwischen Threads einens Prozesses über gemeinsamen Addressraum (Anstelle von aufwendiger inter-prozess-communication (IPC))
    - Erstellen eines Threads wesentlich geringer als einen Prozess zu erzeugen (Faktor 10-100)
    - Schneller Kontextwechsel

- type: md_basic
  id: 25  # (generated)
  front: Was ist der Process Control Block (PCB)?
  back: |+
    Speicherung von Informationen über:
    - *Prozessverwaltung*
    - *Speicherverwaltung* (engl. memory management)
    - *Dateiverwaltung* (engl. file management)

- type: md_basic
  id: 26  # (generated)
  front: Welche Informationen werden für die Speicherverwaltung eines Prozesses benötigt?
  back: |+
    Pointer zu Code-, Daten-, und Stack-Segment
    Anfang und Größe der Segmente.

- type: md_basic
  id: 27  # (generated)
  front: Welche Informationen werden für die Dateiverwaltung eines Prozesses benötigt?
  back: |+
    - Root Verzeichnis
    - File Deskriptoren
    - UID und GID

- type: md_basic
  id: 28  # (generated)
  front: Was ist eine Prozesstabelle
  back: |+
    Eine verkettete Liste von PCBs

- type: md_basic
  id: 29  # (generated)
  front: BS Dienste zur Prozessverwaltung
  back: |+
    - Dienste zur Erzeugung eines Prozesses
    - Dienste zur Terminierung von Prozessen
    - Strategien zur Prozessorzuteilung (Scheduling)
    - Dienste zur Prozessor-Anbundung (Dispatching)

- type: md_basic
  id: 30  # (generated)
  front: Auslöser einer Prozesserzeugung
  back: |+
    - Während der Systeminitialisierung (Init started daemons)
    - Durch andere Prozesse (z.B. via fork)
    - Durch einen Benutzer (Beispiel: Starten eines Programmes)
    - Durch das BS (z.B. Batch-Systeme)

- type: md_basic
  id: 31  # (generated)
  front: Was macht der POSIX-Systemcall `fork`?
  back: "- Kindprozess mit gleichem Speicherabbild (Kopie)\n\t- Auch file descriptors\n
    - Vergabe einer neuen PID\n- Prozesse laufen unabhängig voneinander\n\n"
- type: md_basic
  id: 32  # (generated)
  front: Was ist die Besonderheit bei dem Rückgabewert von `fork`?
  back: |+
    Eltern-Prozess bekommt die PID des Kindes zurückgegeben, während der
    Kindprozess `0` zurückgegeben bekommt. Das kann nützlich sein, um
    z.B. das Speicherabbild des Kindes zu überschreiben.

- type: md_basic
  id: 33  # (generated)
  front: Welche Arten der Prozessterminierung gibt es?
  back: |+
    - Normale Beendigung (freiwillig)
      - `void exit (int status)`
      - `return status` aus `main()`
    - Vorzeitige Beendigung durch Fehler (freiwillig)
      - Fehler wird von Programm abgefangen. Programm terminiert.
    - Vorzeitige Beendigung durch *fatalen* Fehler
      - Exception wird nicht abgefangen, oder kann nicht abgefangen werden (i.e. Segmentation Fault)
    - Terminierung durch einen anderen Prozess
      - Durch senden eines Signals

- type: md_basic
  id: 34  # (generated)
  front: Welche PID hat der Prozess init?
  back: |+
    PID=1. Init ist der erste Prozess der bei einem UNIX(-ähnlichen) System startet.

- type: md_basic
  id: 35  # (generated)
  front: Wer started PID 1?
  back: |+
    Der Kernel.

- type: md_basic
  id: 36  # (generated)
  front: (Extra) Was würde passieren, wenn PID 1 crashed?
  back: |+
    - Alle Kinder sind nun Weisen (Praktisch alle anderen Prozesse)
    - Init ist normalerweise verantwortlich für das Herunterfahren und Neustarten des Systemes
    - PID 1 kann nicht neugestartet werden -> System Neustart notwendig

- type: md_basic
  id: 37  # (generated)
  front: Was ist eine Prozessgruppe?
  back: |+
    Eine Prozessgruppe ist eine Gruppe von einem oder mehreren Prozessen, die für
    Zwecke der Jobsteuerung und Signalverarbeitung als eine einzelne Einheit
    behandelt werden.

    Jeder Prozess inkl. seiner Kinder formen eine Prozessgruppe (Mit PPID identifiziert).

- type: md_basic
  id: 38  # (generated)
  front: Warum sind Prozesshierarchien natürlich in UNIX(-ähnlichen) Systemen?
  back: |+
    Ein Prozess wird von einem bestehenden Prozess erstellt und ist somit sein Kind.
    Der erste Prozess (PID 1) wird allerdings vom BS gestartet.

- type: md_basic
  id: 39  # (generated)
  front: Zombies in Prozesshierarchien
  back: |+
    - Entsteht, wenn ein Kind-Prozess seine Ausführung beendet, bevor der Eltern-Prozess endet.
    - Speicher des Kind-Prozesses wird freigegeben, aber sein Exit-Status wird in den Process Control Block (PCB) geschrieben, wodurch ein Zombie entsteht.
    - Belegen Platz in der Prozesstabelle.
    - Führen keinen Code mehr aus

- type: md_basic
  id: 40  # (generated)
  front: Umgang mit Zombie-Prozessen
  back: |+
    - Der Eltern-Prozess kann `wait` oder `waitpid` verwenden, um auf die Beendigung des Kind-Prozesses zu warten.
    - Der Eltern-Prozess blockiert (wird in die Wait-Queue eingefügt), bis das Kind terminiert.
    - Nach der Beendigung des Kindes kann der Elternprozess den Grund der Terminierung erfragen.
    - Das Lesen des Exit-Status des Kindes entfernt den Zombie-Prozess.

- type: md_basic
  id: 41  # (generated)
  front: Waisenprozesse
  back: |+
    - Waisen entstehen, wenn der Eltern-Prozess vor dem Kind-Prozess endet.
    - Der verwaiste Kind-Prozess wird vom Init-Prozess adoptiert (PPID = 1).

- type: md_basic
  id: 42  # (generated)
  front: Was ist erforderlich, damit ein Waisenprozess zu einem Daemon wird?
  back: |+
    Loslösung von Gruppen-ID und Benutzer-ID und die Umleitung von Filedeskriptoren
    (stdin, stdout, stderr).

- type: md_basic
  id: 43  # (generated)
  front: Prozesshierarchien in Windows
  back: |+
    - Windows hat keine Prozesshierarchien ähnlich wie Unix/Linux.
    - Jeder Windows-Prozess erhält bei der Erstellung einen eindeutigen Handle.
    - Handles können zwischen Prozessen übertragen werden.

- type: md_basic
  id: 44  # (generated)
  front: Welche zwei Hauptaufgaben werden in der Prozessorverwaltung unterschieden?
  back: |+
    - Verwaltung in Dispatcher und Scheduler aufgeteilt. Der Dispatcher realisiert
    Prozess-Zustandsübergänge von rechenwillig nach rechnend, während der Scheduler
    die Reihenfolge der Prozessausführung bestimmt.

- type: md_basic
  id: 45  # (generated)
  front: Welche Rolle spielt der Scheduler in der Prozessorverwaltung?
  back: |+
    - Verwaltet die Warteschlange der rechenwilligen Prozesse (Run
    Queue)
    - Wählt mit Hilfe von Scheduling-Algorithmen den nächste(n) Prozess(e) zur
    Ausführung aus

- type: md_basic
  id: 46  # (generated)
  front: Was macht ein Dispatcher?
  back: |+
    - Implementiert Zustandsübergang zwischen rechnend und rechenwillig
    - Dispatcher entzieht dem rechnenden Prozess/Thread die CPU und teilt sie einem
    anderen rechenbereitem Prozess/Thread zu

- type: md_basic
  id: 47  # (generated)
  front: Abfolge von Dispatching
  back: |+
    1. **Ändert den Zustand** des rechnenden Prozesses zu wartend oder rechenbereit
    2. **Sichert den Kontext** des zuvor rechnenden Prozesses/Threads im PCB
    3. **Lädt den Kontext** des rechenbereiten Prozesses/Threads
    4. **Ändert den Zustand** des rechenbereiten Prozesses zu rechnend

- type: md_basic
  id: 48  # (generated)
  front: Strategische Entscheidungen des Schedulers
  back: |+
    Der Scheduler trifft strategische Entscheidungen darüber, welchen Prozess oder
    Thread er wann und wie lange an die CPU bindet. In Multiprozessor-Systemen
    entscheidet er auch, an welche CPU der Prozess gebunden wird.

- type: md_basic
  id: 49  # (generated)
  front: Wie nutzt der Scheduler das typische Verhalten von Prozessen für das Scheduling?
  back: |+
    Der Scheduler berücksichtigt, dass CPU-Nutzungs-Bursts sich mit I/O-Wartephasen
    abwechseln. Er beachtet sowohl CPU-limitierte als auch I/O-limitierte Prozesse,
    um eine effiziente CPU-Zuteilung zu erreichen.

- type: md_basic
  id: 50  # (generated)
  front: Scheduler-Aktivierung
  back: |+
    Der Scheduler wird bei bestimmten Ereignissen aktiv:
    - Erzeugung neuer Prozesse
    - Terminierung von Prozessen
    - Wenn ein Prozess blockiert wird (z.B. durch I/O oder Semaphoren)
    - Interrupts, wie beispielsweise von einem I/O-Gerät

- type: md_basic
  id: 51  # (generated)
  front: Welche Rolle spielt der Scheduler bei Prozessblockierungen und Interrupts?
  back: |+
    - Prozessblockierungen: Entscheidungen bei Blockierung durch I/O, Semaphoren etc.
    - Belegte Ressourcen: Was passiert, wenn ein blockierender Prozess eine benötigte Ressource belegt?
    - Nächster Prozess: Auswahl, wenn der nächste Prozess die belegte Ressource benötigt.
    - Interrupts: Aufwecken blockierter Prozesse durch I/O-Geräte-Interrupts.
    - Timer-Interrupts: Scheduling-Entscheidungen bei jedem Timer-Interrupt.

- type: md_basic
  id: 52  # (generated)
  front: Thread Implementierungen
  back: |+
    - User-Level-Threads (Scheduling im User-Space)
      - Meistens nur koorperativ (nicht-preemptiv)
    - Kernel-Level-Threads
      - Threadtabelle im Kern. BS kontrolliert Zuteilung.
      - Thread-Operationen führen zu einem Trap in den Kern (Syscall)
    - Hybride Implementierung (n:m Abbildung zwischen n Threads in User-Space und m Kernel Threads)

- type: md_basic
  id: 53  # (generated)
  front: Vorteile von User-Level Threads
  back: |+
    - BS-unabhängig
    - Schnelles Umschalten zwischen User-Level-Threads (keine Syscalls)
    - Anwendungsspezifisches Scheduling

- type: md_basic
  id: 54  # (generated)
  front: Nachteile von User-Level Threads
  back: |+
    - Blockieren eines Threads
    - Threads werden eingesetzt, um blockierende Aufrufe zu parallelisieren
    - Threads können die CPU monopolisieren

- type: md_basic
  id: 55  # (generated)
  front: Vorteile von Kernel-Level Threads
  back: |+
    1. **CPU-Scheduling und Multi-Processing**:
       - Echte Parallelität
    2. **Einfacheres Blocking und I/O-Operationen**:
       - Wenn ein Kernel-Thread eine blockierende I/O-Operation durchführt, kann das Betriebssystem andere Threads im selben Prozess weiterlaufen lassen.
       - User-Level-Threads würden bei einer blockierenden Operation den gesamten Prozess blockieren.
    3. **Prioritätsgesteuertes Scheduling**:
       - Das Betriebssystem kann Kernel-Threads basierend auf Prioritäten planen, was für Echtzeitanwendungen entscheidend sein kann.

- type: md_basic
  id: 56  # (generated)
  front: Nachteile von Kernel-Level Threads
  back: |+
    1. **Overhead bei der Kontextumschaltung**:
       - System Calls notwendig
    2. **Höhere Erzeugungs- und Verwaltungskosten**:
       - Das Erstellen und Verwalten von Kernel-Threads ist oft aufwendiger als bei User-Level-Threads.
       - Jeder Kernel-Thread benötigt eigene Kernel-Ressourcen, was bei vielen Threads zu einem erhöhten Ressourcenbedarf führt.
    3. **Skalierbarkeitsprobleme**:
       - Betriebssysteme begrenzen häufig die Anzahl der Threads, die ein Prozess haben kann, was die Skalierbarkeit von Anwendungen mit vielen Threads einschränken kann.
    4. **Geringere Flexibilität in der Scheduling-Politik**:
       - Bei Kernel-Level-Threads ist das Scheduling meist fest im Kernel verankert, was die Anpassung an spezifische Anwendungsbedürfnisse erschwert.

- type: md_basic
  id: 57  # (generated)
  front: Unix-Threads
  back: "- UNIX-Systeme unterstützen Kernel-Level Threads.\n- LinuxThreads: Erste
    Thread-Implementierung unter Linux.\n\t- Gemeinsame Ressourcen: Adressraum, Datei-Deskriptoren,
    Signale etc.\n\t- Eigene IDs: Jeder Thread hat unterschiedliche PIDs und PPIDs.\n
    \t- Manager-Thread: Benötigt für Erzeugung und Terminierung von Threads.\n\t-
    Thread-Erzeugung: Verwendung des Systemcalls clone().\n- Java Threads (JVM Verwendet
    NPTL)\n\t- Java Thread wird 1:1 auf einen Kernel-Level-Thread abgebildet\n\n"
- type: md_basic
  id: 58  # (generated)
  front: Wichtige POSIX Threads Funktionen
  back: |+
    - pthread_create (Erstellen eines neuen Threads)
    - pthread_exit (Aufrufender Thread wird beendet)
    - pthread_join (Warten auf die Terminierung und Rückgabewert des Threads)

- type: md_basic
  id: 59  # (generated)
  front: Was sind Scheduling Ziele für alle Systeme?
  back: |+
    - **Fairness**: Jeder Prozess soll einen fairen Anteil der CPU erhalten
    - **Balance**: Alle Teile des Systems (CPU, I/O) möglichst effektiv auslasten

- type: md_basic
  id: 60  # (generated)
  front: Was sind Scheduling Ziele für Batch-Systeme?
  back: |+
    - **Durchsatz**: Maximiere Anzahl der Aufträge pro Zeit, Maß für Systemauslastung
    - **Ausführungszeit**: Minimiere Ausführungszeit
    - **CPU Belegung**: Konstante Belegung der CPU

- type: md_basic
  id: 61  # (generated)
  front: Was sind Scheduling Ziele für Interaktive-Systeme?
  back: |+
    - **Antwortzeit**: Minimiere die Antwortzeit für eingehende Anfragen
    - **Proportionalität**: Berücksichtige die Erwartungshaltung der Benutzer

- type: md_basic
  id: 62  # (generated)
  front: Was sind Scheduling Ziele für Echtzeit-Systeme?
  back: |+
    - **Deadlines einhalten**: Vermeide Datenverlust (Soft-Deadlines).
    - **Vorhersagbarkeit**: Vermeide Qualitätsverlust z.B. in Multimediasystemen

- type: md_basic
  id: 63  # (generated)
  front: Was sind Kriterien zur Auswahl von Prozessen
  back: |+
    - Fairness vs. Priorität
    - I/O vs. CPU-Bound Prozesse
    - Wartezeit
    - CPU-Belegung vs. Durchsatz

- type: md_basic
  id: 64  # (generated)
  front: Welche prinzipiellen Scheduling-Klassen gibt es?
  back: |+
    - **Nicht-unterbrechend** (non-preemptive)
    - **Unterbrechend** (preemptive)

- type: md_basic
  id: 65  # (generated)
  front: Was zeichnet nicht-unterbrechendes Scheduling aus?
  back: |+
    Prozesse werden so lange ausgeführt, bis sie blockieren oder freiwillig
    die CPU abgeben.

- type: md_basic
  id: 66  # (generated)
  front: Was zeichnet unterbrechendes Scheduling aus?
  back: |+
    Prozesse werden beim Auftreten von bestimmten Ereignissen (z.B.
    Timer-Interrupt) unterbrochen.

- type: md_basic
  id: 67  # (generated)
  front: Welche drei Scheduling Strategien können für Batch-Systeme genutzt werden?
    Sind sie unterbrechend?
  back: |+
    - **First-Come-First-Served** (FCFS): nicht unterbrechend
    - **Shortest Job First** (SJF): nicht unterbrechend
    - **Shortest Remaining Time Next** (SRTN) unterbrechend

- type: md_basic
  id: 68  # (generated)
  front: Wie ist FCFS aufgebaut?
  back: |+
    - FIFO-Run-Queue (Ready-Queue) mit rechenwilligen Prozessen
    - Prozess wird so lange ausgeführt, bis er blockiert, oder freiwillig die CPU abgibt
    - Bei Abgabe wird der nächste Prozess aus der FIFO Queue aktiv

- type: md_basic
  id: 69  # (generated)
  front: Welchen Nachteil hat die FCFS Scheduling Strategie?
  back: |+
    Der Hauptnachteil der FCFS-Scheduling-Strategie ist der Convoy-Effekt, bei dem
    lange Prozesse kürzere Prozesse in der Warteschlange blockieren, was zu
    ineffizienter CPU-Nutzung und längeren Wartezeiten führt.

- type: md_basic
  id: 70  # (generated)
  front: Warum sind "Shortest Job First" und "Shortest Remaining Time Next" ungeeignet
    für Scheduling in interaktiven Systemen?
  back: |+
    Die Ausführungszeiten müssen vorab bekannt sein.

- type: md_basic
  id: 71  # (generated)
  front: Wann wird ein Prozess bei "Shortest Remaining Time Next" unterbrochen?
  back: |+
    Bei Ankunft neuer Prozesse.

- type: md_basic
  id: 72  # (generated)
  front: Wie funktioniert die SJF Scheduling Strategie?
  back: |+
    - CPU wird einem Prozess mit der kürzesten Rechenzeit zugewiesen

- type: md_basic
  id: 73  # (generated)
  front: Wann ist die SJF Scheduling Strategie optimal?
  back: |+
    Wenn alle Jobs am Anfang vorliegen und alle Rechenzeiten bekannt sind.

- type: md_basic
  id: 74  # (generated)
  front: Wie können auch Prozesse mit unbekannter Rechenzeit mit der SJF Scheduling
    Strategie verarbeitet werden?
  back: |+
    Die Rechenzeit wird in Phasen approximiert. Dabei wird die nächste Rechenphase
    abgeschätzt und mit der letzten (tatsächlichen) Ausführungszeit korrigiert.

    TODO: Formel

- type: md_basic
  id: 75  # (generated)
  front: Beschreibe wie die SRTN Scheduling Strategie funktioniert.
  back: |+
    SRTN (Shortest Remaining Time Next) ist die unterbrechbare Variante von Shortest Job First (SJF).

    1. Sobald ein neuer Prozess rechenwillig wird, wird seine Gesamt-Rechenzeit mit
    der verbleibenden Zeit des aktiven Prozesses verglichen
    2. Ist die Rechenzeit des neuen Prozesses kürzer, wird der aktive Prozess unterbrochen.

- type: md_basic
  id: 76  # (generated)
  front: Nenne zwei Scheduling Strategien für interaktive Systeme.
  back: |+
    - **Round-Robin Scheduling** (RR)
    - **Priority Scheduling**

- type: md_basic
  id: 77  # (generated)
  front: Was passiert, wenn das Zeitquantum bei m Round-Robin Scheduling Algorithmus
    zu kurz gewählt wird?
  back: |+
    Es werden zu viele teure Kontextwechsel erzeugt.

- type: md_basic
  id: 78  # (generated)
  front: Was passiert, wenn das Zeitquantum bei m Round-Robin Scheduling Algorithmus
    zu lang gewählt wird?
  back: |+
    Das Verhalten ist ähnlich wie bei einem FCFS-Scheduling, was zu langen
    Wartezeiten für andere Prozesse und einer verringerten Systemreaktivität führt.

- type: md_basic
  id: 79  # (generated)
  front: Wie heißen die zwei vorgestellten Scheduling-Strategien für Echtzeit-Systeme?
  back: |+
    - **Earliest Deadline First** (EDF)
    - **Rate-Monotonic Scheduling** (RMS)

- type: md_basic
  id: 80  # (generated)
  front: Beschreibe wie Priority Scheduling für interaktive Systeme funktioniert
  back: |+
    - Jedem Prozess wird eine Priorität zugewiesen
    - CPU wird einem rechenwilligen Prozess mit der höchsten Priorität zugewiesen
    - Prozesse mit gleicher Priorität werden in einer Queue verwaltet -> **Eine Queue pro Priorität**
    - **Kontextwechsel**: Sobald *höher-prioritisierter*, *rechenwilliger* Prozess bereit ist

- type: md_basic
  id: 81  # (generated)
  front: Welche Probleme entstehen wenn beim Priority Scheduling die Prioritäten nur
    statisch gewählt werden?
  back: |+
    1. **Prozesse verhungern**: Niedrig prioritisierte Prozesse könnten keine CPU Zeit bekommen und verhungern
    2. **Flexibilität**: Gerade bei interaktiven System ändert sich die Priorität häufig.
    3. **Vorausplanen** der Priorität schwierig bei interaktiven Systemen

- type: md_basic
  id: 82  # (generated)
  front: Wie könnte eine Dynamische Prioritisierung (z.B. nach einem Timer-Interrupt)
    ablaufen?
  back: |+
    - **Prioritätsverringerung**: Vermeiden, dass zu hoch-prioritisiere Prozesse endlos laufen
    - **Prioritätserhöhung**: Vermeiden, dass niedrig-prioritisiere Prozesse verhungern
    - **I/O-Boost**: Kurzzeitige Bervorzugung von I/O-Bound Prozessen

- type: md_basic
  id: 83  # (generated)
  front: Welche Datenstruktur kann für die Dynamische Prioritisierung genutzt werden?
  back: |+
    Multilevel-Feedback-Warteschlange

- type: md_basic
  id: 84  # (generated)
  front: Was ist ein weiches Echtzeit System?
  back: |+
    - Es wird toleriert, dass nicht alle Deadlines eingehalten werden (**soft deadlines**)
    - Beispiel: Verlieren von (Netzwerk-)Paketen während einer Videokonferenz

- type: md_basic
  id: 85  # (generated)
  front: Was ist ein hartes Echtzeit System?
  back: |+
    - Harte Deadlines die eingehalten werden müssen
    - Bsp. Sicherheitskritische Anwendungen, oder Prozessabläufe

- type: md_basic
  id: 86  # (generated)
  front: Earliest Deadline First (EDF)
  back: |+
    - CPU wird dem Prozess der *nächsten* **Deadline** zugeordnet
    - Preemptive: Prozess wird unterprochen, **sobald** ein Prozess mit einer früheren Deadline rechenwillig ist.
    - Non-preemptive (Prozess muss kooperieren. Kontextwechsel nach Beendigung, oder Yield)

- type: md_basic
  id: 87  # (generated)
  front: Rate-Monotonic Scheduling (RMS)
  back: "- Für **periodische Prozesse**\n- Prozess-Priorität in Abhängigkeit von der
    Periode zugeordnet\n- Deadline entspricht dem Ende der Periode \n- Periode mit
    der höchsten Frequenz (kleinste Periode) -> Höchste Priorität\n- Periode wird
    statisch vergeben\n\n"
- type: md_basic
  id: 88  # (generated)
  front: Was ist das Hauptziel des Mehrschichtigen Schedulings?
  back: |+
    Das Hauptziel des Mehrschichtigen Schedulings ist es, nicht alle rechenwilligen Prozesse sofort im Speicher zu lagern, sondern dies vorab effizient zu organisieren.

- type: md_basic
  id: 89  # (generated)
  front: Wie unterscheidet sich preemptive von non-preemptive Scheduling?
  back: |+
    Preemptive Scheduling erlaubt die Unterbrechung eines laufenden Prozesses, während non-preemptive Scheduling den Prozess bis zu seinem Ende ohne Unterbrechung laufen lässt.

- type: md_basic
  id: 90  # (generated)
  front: Was ist die Aufgabe des Short-Term-Schedulers (STS)?
  back: |+
    Der Short-Term-Scheduler (STS) wählt geeignete Prozesse aus der Run-Queue (Ready-Queue) für die Ausführung aus und verwendet dabei verschiedene vorgestellte Verfahren.

- type: md_basic
  id: 91  # (generated)
  front: 'Wahr oder Falsch: Der Dispatcher ist immer Teil des Short-Term-Schedulers.'
  back: |+
    Wahr. Der Dispatcher ist in der Regel ein Bestandteil des Short-Term-Schedulers und wird sehr häufig aufgerufen.

- type: md_basic
  id: 92  # (generated)
  front: Was ist die Funktion des Medium-Term-Schedulers (MTS)?
  back: |+
    Der Medium-Term-Scheduler (MTS) entscheidet, ob ein Prozess in den Speicher eingelagert werden soll und ist ein Teil des Swapping-Mechanismus.

- type: md_basic
  id: 93  # (generated)
  front: Erkläre die Rolle des Long-Term-Schedulers (LTS).
  back: |+
    Der Long-Term-Scheduler (LTS) zielt darauf ab, einen guten Mix aus I/O-intensiven und rechenintensiven Prozessen zu erreichen und entscheidet über die Einlagerung neuer Aufträge in den Arbeitsspeicher.

- type: md_basic
  id: 94  # (generated)
  front: Wie beeinflusst der Long-Term-Scheduler den Grad des Multiprogrammings?
  back: |+
    Der Long-Term-Scheduler steuert, wie viele Prozesse gleichzeitig im Arbeitsspeicher liegen, und beeinflusst somit den Grad des Multiprogrammings.

- type: md_basic
  id: 95  # (generated)
  front: Wann wird der Long-Term-Scheduler typischerweise aufgerufen?
  back: |+
    Der Long-Term-Scheduler wird aufgerufen, sobald ein neuer Prozess erzeugt wird, und entscheidet, ob dieser zur Ready-Queue hinzugefügt werden soll.

- type: md_basic
  id: 96  # (generated)
  front: 'Wahr oder Falsch: Der Long-Term-Scheduler ist immer in Betriebssystemen
    vorhanden.'
  back: |+
    Falsch. Der Long-Term-Scheduler ist nicht immer vorhanden, zum Beispiel nicht unter Linux.

- type: md_basic
  id: 97  # (generated)
  front: Was ist der Unterschied zwischen Short-Term- und Long-Term-Scheduling?
  back: |+
    Short-Term-Scheduling befasst sich mit der Auswahl von Prozessen zur Ausführung aus der Ready-Queue, während Long-Term-Scheduling entscheidet, welche Prozesse in den Speicher gelangen und den Multiprogramming-Grad beeinflusst.

- type: md_basic
  id: 98  # (generated)
  front: Wie werden Threads unter Linux für das Scheduling behandelt?
  back: |+
    Unter Linux werden Threads 1:1 auf Kernel-Level-Threads abgebildet, was zu einem thread-basierten Scheduling führt.

- type: md_basic
  id: 99  # (generated)
  front: Welche drei Thread-Klassen unterscheidet Linux beim Scheduling?
  back: |+
    Linux unterscheidet zwischen Echtzeit-FIFO, Echtzeit-Round-Robin und Timesharing-Threads.

- type: md_basic
  id: 100  # (generated)
  front: Was war die Besonderheit des Linux-Schedulers bis zur Kernelversion 2.6?
  back: |+
    Bis zur Kernelversion 2.6 verwendete Linux den O(1)-Scheduler, der auf Priority Scheduling mit 140 Prioritäten basierte.

- type: md_basic
  id: 101  # (generated)
  front: Was ist der Completely-Fair-Scheduler (CFS) und wie unterscheidet er sich
    vom O(1)-Scheduler?
  back: |+
    Der Completely-Fair-Scheduler (CFS), eingeführt ab Kernelversion 2.6, verwendet eine Red-Black Tree basierte Run-Queue und ordnet Prozesse nach ihrer bereits verbrauchten CPU-Rechenzeit an, im Gegensatz zum O(1)-Scheduler.

- type: md_basic
  id: 102  # (generated)
  front: Wie sind die 140 Prioritäten im Linux-Scheduling verteilt?
  back: |+
    Von den 140 Prioritäten unter Linux sind 0-99 für Echtzeit-Threads und 100-139 für Timesharing-Threads reserviert.

- type: md_basic
  id: 103  # (generated)
  front: 'Wahr oder Falsch: Echtzeit-Threads unter dem Standard-Linux-Kernel können
    für Echtzeitanwendungen genutzt werden.'
  back: |+
    Falsch. Echtzeit-Threads können mit dem Standard-Linux-Kernel nicht für Echtzeitanwendungen genutzt werden.

- type: md_basic
  id: 104  # (generated)
  front: Welche Herausforderungen ergeben sich beim Multicore-/Multiprozessorscheduling?
  back: |+
    Zu den Herausforderungen gehören die Zuordnung von Prozessen zu einzelnen Kernen/Prozessoren, unterschiedliche Charakteristika der Recheneinheiten und die Balance zwischen Scheduling-Qualität und -geschwindigkeit.

- type: md_basic
  id: 105  # (generated)
  front: Was ist das Ziel beim Scheduling von N Prozessen auf M Prozessoren und warum
    ist es komplex?
  back: |+
    Ziel ist es, einen Schedule zu finden, der die Gesamtausführungszeit minimiert. Für M>1 ist dies äquivalent zum multiway number partitioning und somit NP-hard, was es komplex macht.

- type: md_basic
  id: 106  # (generated)
  front: Was sind die Unterschiede zwischen Time Sharing und Space Sharing im Kontext
    des Schedulings?
  back: |+
    Time Sharing ermöglicht die abwechselnde Nutzung von Ressourcen, während Space Sharing abhängigen Prozessen den direkten Austausch und gemeinsame Ressourcennutzung erlaubt.

- type: md_basic
  id: 107  # (generated)
  front: Was versteht man unter Gang Scheduling?
  back: |+
    Gang Scheduling ist eine Kombination von Time und Space Sharing, bei der abhängige Prozesse als eine Einheit behandelt werden und gemeinsame Zeitscheiben für die Ausführung erhalten.

- type: md_basic
  id: 108  # (generated)
  front: Erkläre das Konzept der "Globalen Warteschlange" im Kontext von CPU-Management
    und Multi-CPU Scheduling.
  back: |+
    - Alle CPUs nutzen eine gemeinsame Warteschlange für Prozesse
    - Gute CPU-Auslastung und Fairness für alle Prozesse
    - Schlechte Skalierbarkeit durch lock contention und schlechte Cache Lokalität

- type: md_basic
  id: 109  # (generated)
  front: Was sind die Vorteile einer Warteschlange für jede CPU bei Multi-CPU Scheduling?
  back: |+
    Implementierung, Skalierbarkeit durch die Vermeidung von lock contention, und
    bessere Cache Lokalität.

- type: md_basic
  id: 110  # (generated)
  front: Nenne einen Nachteil der Verwendung einer Warteschlange für jede CPU.
  back: |+
    Ungleiche Auslastung der CPUs, was zu Unfairness gegenüber Prozessen führen kann.

- type: md_basic
  id: 111  # (generated)
  front: Was ist die hybridge Implementierung von CPU und Prozess Warteschlangen?
  back: |+
    - Verwendung einer globalen mit lokalen Warteschlangen
    - Verschiebung von lokale Warteschlange in eine andere
       - Gute Auslastung
       - Wiederverwendung von Daten im Cache

- type: md_basic
  id: 112  # (generated)
  front: Was versteht man unter der Heterogenität von Prozessen?
  back: |+
    - Ausführungszeit eines Prozesses stark von der Wahl des Prozessors ab
    - **Cache Reuse**: Weiternutzen von existierenden Daten im Cache eines Prozessors
    - **Hitze**: Beispiel: Perfomance vs. Efficiency Cores

- type: md_basic
  id: 113  # (generated)
  front: Was ist NUMA (Non-Uniform Memory Access)
  back: |+
    Zugriffszeit auf den Arbeitsspeicher ist nicht für alle Prozessoren identisch.
    Prozesse sollten möglichst nahe an dem von ihnen benötigten Speicher ausgeführt werden.

- type: md_basic
  id: 114  # (generated)
  front: Nenne eine alternative Architektur, die den Kernel parallelisiert
  back: |+
    - Konzept heißt Multi-Kernel
    - Bisher:
       - Bei paralleler Ausführung werden oftmals kritische Abschnitte geschützt (skaliert schlecht)
       - Kernel muss für alle Applikationen möglichst gut sein
    - Aufteilung: Ein Kern pro Rechenkern oder NUMA-Knoten
    - Zustandsreplizierung zwischen verschiedenen Kernen

- type: md_basic
  id: 115  # (generated)
  front: Datenzentrischer Kernel
  back: |+
    - Betriebsystem aggregiert und verwaltet viele Daten
    - Idee: Zentralisieren aller Daten in einer Datenbank
    - Bisher nur ein Konzept

- type: md_basic
  id: 116  # (generated)
  front: Welcher der folgenden Systemcalls wird unter Unix für die Behandlung von
    Signalen verwendet? pause, alarm, kill, sigaction, wait, pthread_kill?
  back: |+
    Unter Unix wird der Systemaufruf `sigaction` verwendet, um die Behandlung von Signalen zu steuern.

- type: md_basic
  id: 117  # (generated)
  front: Welche der folgenden Systemcalls werden unter Unix für die Prozessverwaltung
    verwendet? wait, select, pthread_create, creat, getcpu, fork
  back: |+
    wait, fork

- type: md_basic
  id: 118  # (generated)
  front: Was sind notwendige Bedingungen für das Auftreten eines Deadlocks nach Coffman
    et al. (1971)? mutual exclusion, hold-and-wait, circular preemption, no-preemption,
    circular wait, mutual preemption
  back: |+
    Mutual exclusion, hold-and-wait, no-preemption, circular wait

- type: md_basic
  id: 119  # (generated)
  front: Die Größe welcher der folgenden Segmente sind dem Betriebssystem bereits
    unmittelbar nach dem Programmstart bekannt? .heap, .rodata, .text, .data
  back: |+
    .rodata, .text, .data

- type: md_basic
  id: 120  # (generated)
  front: Nenne die 4 Betriebsarten eines Betriebsystems.
  back: |
    - Echtzeitbetrieb (Real-time mode)
    - Dialogbetrieb (Interactive mode)
    - Stapelverarbeitung (Batch processing):
    - Transaktionsbetrieb (Transaction processing):
      In dieser Betriebsart werden Transaktionen, oft in Datenbanken, verarbeitet,
      wobei die Integrität der Daten trotz gleichzeitiger Zugriffe mehrerer Benutzer
      oder Systeme gewährleistet werden muss.
